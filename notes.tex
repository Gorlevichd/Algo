\documentclass[a4paper, 12pt]{article}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian, english]{babel}
\usepackage{statmath}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{color}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{mathtools}
\hypersetup{
    colorlinks=true,
    linktoc=all,
    linkcolor=black,
    urlcolor=black}
    
\setlength{\parindent}{0pt}
\begin{document}

\part{Роль алгоритмов в вычислениях}

\section{Алгоритмы}

\textbf{Алгоритм} - любая корректно определенная вычислительная процедура на вход которой подается некоторый набор величин и 
результатом выполнения которой явялется выходной набор значений

\textbf{Алгоритм корректен}, если для каждого ввода результатом его работы является корректный вывод

\section{Структуры данных}

\textbf{Структура данных} - способ хранения и организации данных, облегчающий доступ к этим данным и их модификацию

\section{Сложные задачи}

Задачи, для которых неизвестны эффективные методы решения называются \textbf{NP-полные}

Они представляют интерес:

\begin{enumerate}
    \item Не доказано, что эффективного алгоритма не существует
    \item Если эффективный алгоритм существует хотя бы для одной NP-полной задачи, то его можно сформулировать и для остальных
    \item Некоторые NP-полные задачи похожи на задачи, для которых известны эффективные алгоритмы
\end{enumerate}

\section{Алгоритмы как технология}

\subsection{Эффективность}

Алгоритмы часто различаются по эффективности, различия могут быть значительнее, чем те, что вызваны разной мощностью аппаратного обеспечения

\underline{Пример:}

\textit{Сортировка вставкой:} требует время, которое оценивается как $c_1n^2$, где $c_1$ - константа, не зависящая от n.
Таким образом, время работы этого алгоритма пропорционально $n^2$.

\textit{Сортировка слиянием:} требует время, приблизительно равное $c_2nlgn$.

Для этих двух методов зависимые множители относятся как $\frac{lgn}{n}$. 
Для маленьких n сортировка вставкой работает быстрее, но для больших n проявляется преимущество сортировки слиянием.

\part{Приступаем к изучению}

\section{Сортировка вставкой}

\textbf{Вход:} Последовательность из n чисел $<a_1, a_2, \cdots, a_n>$

\textbf{Выход:} Перестановка $<a_1', a_2', \cdots, a_n'>$ входной последовательности таким образом, что $a_1' \leq a_2' \leq \cdots \leq a_n'$

Сортируемые числа известны под названием \textit{ключи (keys)}

\textbf{Псевдокод:}

\begin{lstlisting}
    Insertion_Sort(A):
        for j = 2 to length[A]:
            key = A[j]
            # Insert A[j] into sorted sequence A[1:j-1]
            i = j - 1
            while i > 0 and A[i] > key:
                do A[i + 1] = A[i]
                i = i - 1
            A[i + 1] = key
\end{lstlisting}

\subsection{Инварианты цикла и корректность сортировки вставкой}

В начале каждой итерации цикла for подмассив A[1:j-1] содержит те элементы, которые были в нем с самого начала, 
но расположенные в отсортированном порядке. Это свойство элементов A[1:j-1] называется \textbf{инвариантом цикла}

Инварианты цикла позволяют понять, что алгоритм работает корректно. Необходимо показать, 
что инварианты циклов обладают следующими тремя свойствами:

\begin{enumerate}
    \item \textbf{Инициализация:} Они справедливы перед первой инициализацией цикла
    \item \textbf{Сохранение:} Если они истинны перед очередной итерацией цикла, то остаются истинны и после нее
    \item \textbf{Завершение:} По завршении цикла инварианты позволяют убедиться в правильности алгоритма
\end{enumerate}

Если выполняются первые два свойства, то инварианты \textbf{остаются истинными перед каждой очередной итерацией цикла}

\underline{Доказательства}

\textbf{Инициализация:}

j = 2 $\rightarrow$ подмножество элементов A[1:j-1] состоит из одного элемента A[1], сохраняющего исходное значение. 
Более того, в этом подмножестве элементы рассортированы. Инвариант соблюдается

\textbf{Сохранение:} 

В теле внешного цикла происходит сдвиг элементов A[j - 1], A[j - 2], A[j - 3], ... на одну позицию вправо до тех пор, пока не освободится подходящее
место для элемента A[j]

\textbf{Завершение:}

При сортировке методом включений внешний цикл завершается, когда j превышает n, т.е. когда j = n+1. 
Подставим в формулировку инварианта цикла значение n+1, получим утверждение: в подмножестве элементов A[1:n]
находятся те же элементы, что и были в нем до начала работы алгоритма, но расположенные в отсортированном порядке.
Подмножество A[1:n] и есть массив A. Таким образом, весь массив отсортирован.

\section{Анализ алгоритмов}

\textbf{Анализ алгоритма} заключается в том, чтобы предсказать требуемые для его выполнения ресурсы. 
Чаще всего определяется \underline{время выполнения}.

Путем анализа нескольких алгоритмов можно выбрать наиболее эффективный

\underline{Модель ресурсов:}

В качестве технологии реализации принята модель обобщенной однопроцессороной машины с \textit{памятью с произвольным доступом} (RAM).
Команды процессора выполняются последовательно, одновременно выполняемые операции отсутствуют.

\underline{Команды процессора:}

\begin{enumerate}
    \item Арифметические операции
    \item Операции перемещения данных
    \item Управляющие (условное и безусловное ветвление, вызов подпрограммы, возврат из нее)
\end{enumerate}

Для выполнения каждной такой инструкции требуется определенный фиксированный промежуток времени

\underline{Типы данных:}

\begin{enumerate}
    \item Целочисленный тип данных
    \item Тип чисел с плавающей точкой
\end{enumerate}

Существует верхний предел размера слова данных

Например, если обрабатываются входные данные с максимальным значением n, обычно предполагается,
что целые числа представлены $clgn$ битами, где $c$ - произвольная константа $\infty \geq c \geq 1$.

Вычисление $2k$ рассматривается как элементарная операция, если $k$ достаточно малое число

\subsection{Анализ алгоритма Insertion Sort}

Для анализа необходимо использовать \textbf{размер входных данных}. Для некоторых задач это может быть \textit{количество входных элементов},
для других - \textit{общее количество бит}

\textbf{Время работы} измеряется в количестве элементарных операций, которые необходимо выполнить.

Предположим, что для выполнения строки псевдкода требуется фиксированное время. Одна и та же строка $i$ выполняется за время $c_i$

$t_j$ - количество проверок условия в цикле while. При нормальной работе циклов условие проверяется на один раз больше, чем 
выполняется тело цикла

\begin{lstlisting}[mathescape = true]
    Insertion_Sort(A):
        for j = 2 to length[A]                  #$c_1n$
            key = A[j]                          #$c_2(n-1)$
            i = j - 1                           #$c_3(n - 1)$
            while i > 0 and A[i] > key:         #$c_4(sum_{j = 2}^n t_j)$
                A[i + 1] = A[i]                 #$c_5(sum_{j = 2}^n (t_j - 1))$
                i = i - 1                       #$c_6(sum_{j = 2}^n (t_j - 1))$
            A[i + 1] = key                      #$c_7(n - 1)$
\end{lstlisting}

\textbf{Время работы алгоритма} - это сумма времени промежутков времени, необходимых для выполнения каждой входящей в его состав
исполняемой инструкции

\[T(n) = c_1n + c_2(n - 1) + c_3(n - 1) + c_4\sum_{j = 2}^n t_j + 
c_5 \sum_{j = 2}^n (t_j - 1) + c_6 \sum_{j = 2}^n (t_j - 1) + c_7(n - 1)\]

Если массив уже отсортирован, то $t_j = 1$

Если массив отсортирован в обратном порядке, то это наихудший случай. 
Каждый элемент необходимо сравнивать со всеми элементами уже отсортированного множества.

Так что $\forall j: t_j = j$

$$
    \sum_{j = 2}^n j = \frac{n(n + 1)}{2} - 1
$$

$$
    \sum_{j = 2}^n (j - 1) = \frac{n(n - 1)}{2}
$$

$$
    T(n) = c_1n + c_2(n - 1) + c_3(n - 1) + c_4(\frac{n(n + 1)}{2} - 1) + 
    c_5(\frac{n(n - 1)}{2}) + c_6(\frac{n(n - 1)}{2}) + c_7(n - 1)
$$

$$
    T(n) = (\frac{c_4 + c_5 + c_6}{2})n^2 + (c_1 + c_2 + c_3 + \frac{c_4 + c_5 + c_6}{2} + c_7)n - (c_2 + c_3 + c_5 + c_7)
$$

Это время работы можно записать как $an^2 + bn + c$, где константы зависят от $c_i$. Таким образом, это квадратичная функция $n^2$

\subsection{Наихудшее и среднее время работы}

В основном уделяется внимание \textbf{наихудшему времени работы}

\begin{enumerate}
    \item Наихудший случай - верхний предел
    \item В некоторых алгоритмах наихудший случай встречается довольно часто
    \item Характер поведения усредненного времени работы часто ничем не лучше поведения для наихудшего случая
\end{enumerate}

\subsection{Порядок возрастания}

Во внимание будет приниматься \textbf{только главный член формулы}. \textbf{Постоянные множители будут игнорироваться},
так как для оценки вычислительной эффективности алгоритма с большими входными данными они менее важны, чем порядок роста

Обычно один алгоритм считается \textbf{эффективнее} другого, если \textbf{время его работы в наихудшем случае имеет более низкий порядок роста}

\part{Разработка алгоритмов}

В алгоритме, работающем по методу вставок, применяется \textbf{инкрементный подход}: располагая отсортированным 
подмассивом A[1:j-1], мы помещаем очередной элемент A[j] туда, где он должен находится,
в результате чего получаем отсортированный подмассив A[1:j]

\section{Метод декомпозиции}

Сложная задача разбивается на несколько более простых, которые подобн-ы исходной задаче, но имеют меньший объем.
Далее эти вспомогательные задачи решаются рекурсивным методом, после чего 
полученные решения комбинируются с целью получить решение исходной задачи

\underline{Разделяй и властвуй}

\begin{enumerate}
    \item \textbf{Разделение} задачи на несколько подзадач
    \item \textbf{Покорение} - рекурсивное решение этих подзадач. Когда объем подзадачи достаточно мал, 
    выделенные подзадачи решаются непосредственно
    \item \textbf{Комбинирование} решений исходной задачи из решений вспомогательной задачи 
\end{enumerate}

\subsection{Алгоритм сортировки слиянием}

\begin{enumerate}  
    \item \textbf{Разделение:} Сортируемая последовательность разбивается на две меньшие последовательности, 
    каждая из которых содержит n/2 элементов
    \item \textbf{Покорение:} Сортировка обеих вспомогательных последовательностей методом слияния
    \item \textbf{Комбинирование:} Слияние двух отсортированных последовательностей для получения конечного результата
\end{enumerate}

Рекурсия достигает своего нижнего пределга, когда длина сортируемой последовательности становится равно 1.
В этом случае вся работа уже сделана, поскольку любую такую последовательность можно считать упорядоченной.

Основная операция, которая производится в процессе сортировки слиянияем - 
это \textbf{объединение двух отсортированных последовательностей}.

Это делается с помощью вспомогательной функции Merge(A, p, q, r), где A - массив, p, q, r - индексы, такие что $p \leq q < r$.

В этой процедуре предполагается, что элементы подмассивов A[p:q] и A[q + 1:r] упорядочены. 
Она сливает эти два подмассива в один отсортированный, элементы которого заменяют текущие элементы массива A[p:r]

Для выполнения процедуры Merge требуется время $\Theta(n)$, где n = r - p + 1.

Аналогия с картами:

Из двух младших карт выбрать наиболее младшую, извлечь ее из соответствующей стопки и поместить в выходную стопку. 
Этот шаг повторяется до тех пор, пока в одной стопке не окажется 0 карт. После этого все оставшиеся в другой стопке карты 
необходимо поместить в выходную стопку.

Дополнительная идея: Используем \textbf{сигнальную карту}
В ходе каждого шага не приходится проверять является ли каждая из двух стопок пустой. 
Не существует карт, достоинство которых больше сигнальной карты. Процесс продолжается до тех пор,
пока карты в обеих стопках не окажутся сигнальными. 
В выходной стопке должна содержаться r - p + 1 карта $\rightarrow$ на этом значении \textbf{процесс можно остановить}

\underline{Псевдокод}

\begin{lstlisting}[mathescape = true]
    Merge(A, p, q, r):
        n1 = q - p + 1                      #Calculate len A[p:q]
        n2 = r - q                          #Calculate len A[q+1:r]
        # Create arrays L[1:n1+1], R[1:n2+1]
        for i=1 to n1:                      #Copy A elements to L, R
            L[i] = A[p + i - 1]
        for j = 1 to n2:
            R[j] = A[q + j]
        L[n1 + 1] = $\infty$                # Add signal values
        R[n2 + 1] = $\infty$
        i = 1
        j = 1
        fpr k = p to r:
            if L[i] $\leq$ R[j]:
                A[k] = L[i]
                i = i + 1
            else:
                A[k] = R[j]
                j = j + 1
\end{lstlisting}

\underline{Инвариант цикла}

\begin{enumerate}
    \item \textbf{Инициализация:} Перед первой итерацией цикла k = p, поэтому подмассив A[p:k-1] пуст.
    Он содержит k-p = 0 наименьших элементов массивов L, R. Поскольку i=j=1, элементы L[i], R[j] -
    наименьшие элементы массивов L и R, не скопированные обратно в массив A
    \item \textbf{Сохранение:} Предположим, что L[i] $\leq$ R[j]. Тогда L[i] наименьший элемент еще
    не скопированный в массив A. Поскольку в массиве A[p:k-1] содержится k-p наименьших элементов,
    после копирования L[i] в A[k] в подмассиве A[p:k] будет содержаться k-p+1 наименьших элементов.
    В результате увеличения k в цикле for и i инварианта цикла сохраняется. Аналогично для L[i] $\geq$ R[j]
    \item \textbf{Завершение:} Алгоритм завершается, когда $k = r + 1$. 
    В соответствии с инвариантом цикла подмассив A[p:k-1], т.е. массив A[p:r] содержит k - p = r - p + 1 наименьших элементов
    массивов L[1:n1+1], R[1:n2+1] в отсортированном порядке. Все они, кроме сигнальных, скопированны в исходный массив.
\end{enumerate}

\textbf{Merge Sort(A, p, r)}:

Производит сортировку элементов в подмассиве A[p:r]. Если справедливо неравентсво $p \geq r$,
в массиве содержится не больше 1 элемента и он является \textbf{уже отсортированным}

\underline{Псевдокод}

\begin{lstlisting}
    Merge_Sort(A, p, q):
        if p < r:
            q = \lfloor (p + r)/2 \rfloor
            Merge_Sort(A, p, q)
            Merge_Sort(A, q + 1, r)
            Merge(A, p, q, r)
\end{lstlisting}

\subsection{Анализ алгоритмов, построенных на принципе "разделяй и властвуй"}

Время работы можно описать с помощью \textbf{рекуррентного уравнения},
которое выражает время решения задачи n через решения задач для меньших входных данных

Обозначим время решения задачи через $T(n)$

$$
    T(n) = \Theta(1), n \leq c
$$

c - некоторая заранее известная константа

Если задача делится на a подзадач, объем каждой из которых равен 1/b от исходной задачи:

Для решения подзадачи потребуется время $T(n/b)$, для решения a задач: aT(n/b)

Предположим, что на разбитие задачи расходуется время $D(n)$, на переход к исходной задаче $C(n)$

Тогда:

$$
    T(n) = \begin{cases}
        \Theta(1), c \leq n \\
        aT(n/b) + D(n) + C(n), c > n
    \end{cases}
$$

\subsection{Анализ алгоритма Merge Sort}

\begin{enumerate}
    \item \textbf{Разделение}: Определяет, где находится середина подмассива $D(n) = \Theta(1)$
    \item \textbf{Властвование}: Рекуррентно решаются 2 подзадачи размер которых составляет 1/2 от исходной. $2T(n/2)$
    \item \textbf{Комбинирование}: Процедура Merge. Работает за $C(n) = \Theta(n)$
\end{enumerate}

$$
    T(n) = \begin{cases}
        \Theta(1), c = 1 \\
        2T(n / 2) + \Theta(1) + \Theta(n) = 2T(n / 2) + cn, n > 1
    \end{cases}
$$

Полностью раскрытое дерево имеет $lgn + 1$ уровень, а вклад каждого уровня - cn $\rightarrow$ cnlgn - cn $\rightarrow \Theta(nlgn)$


\end{document}
